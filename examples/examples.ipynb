{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples of using HTOF:\n",
    "### This notebook contains a variety of use case examples for htof."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Simple fit to hip 2007 astrometry of beta pic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First way: Using the Astrometry() convienience class (no parallax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "No file with name containing 27321 or 27321 or 027321 found in htof/test/data_for_tests/Hip21",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-23391caf58bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mpmDec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m81.96\u001b[0m  \u001b[0;31m# mas/year\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# generate fitter and parse intermediate data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m astro = Astrometry('Hip21', '27321', os.path.join('htof/test/data_for_tests/', 'Hip21'), \n\u001b[0m\u001b[1;32m     13\u001b[0m                    \u001b[0mcentral_epoch_ra\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1991.25\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                    \u001b[0mcentral_epoch_dec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1991.25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'jyear'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_degree\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envs/htof/lib/python3.8/site-packages/htof/main.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_choice, star_id, intermediate_data_directory, fitter, data, central_epoch_ra, central_epoch_dec, format, fit_degree, use_parallax, central_ra, central_dec, use_catalog_parallax_factors, along_scan_error_scaling, **kwargs)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mThisDataParser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparsers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata_choice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             data = ThisDataParser.parse_and_instantiate(star_id=star_id,\n\u001b[0m\u001b[1;32m     50\u001b[0m                                                         intermediate_data_directory=intermediate_data_directory)\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_along_scan_errs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malong_scan_error_scaling\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envs/htof/lib/python3.8/site-packages/htof/parse.py\u001b[0m in \u001b[0;36mparse_and_instantiate\u001b[0;34m(cls, star_id, intermediate_data_directory, **kwargs)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;31m#  a DataParser object immediately when you want to parse.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstar_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintermediate_data_directory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envs/htof/lib/python3.8/site-packages/htof/parse.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, star_id, intermediate_data_directory, error_inflate, attempt_adhoc_rejection, reject_known, **kwargs)\u001b[0m\n\u001b[1;32m    566\u001b[0m               reject_known=True, **kwargs):\n\u001b[1;32m    567\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'star_id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstar_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m         \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_header\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstar_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintermediate_data_directory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m         raw_data = self.read_intermediate_data_file(star_id, intermediate_data_directory,\n\u001b[1;32m    570\u001b[0m                                                     skiprows=13, header=None, sep=r'\\s+')\n",
      "\u001b[0;32m~/envs/htof/lib/python3.8/site-packages/htof/parse.py\u001b[0m in \u001b[0;36mread_header\u001b[0;34m(self, star_id, intermediate_data_directory)\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread_header\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstar_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintermediate_data_directory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mfpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_intermediate_data_file_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstar_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintermediate_data_directory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envs/htof/lib/python3.8/site-packages/htof/parse.py\u001b[0m in \u001b[0;36mget_intermediate_data_file_path\u001b[0;34m(star_id, intermediate_data_directory)\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0mfilepath_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatch_filename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstar_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_list\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             raise FileNotFoundError('No file with name containing {0} or {1} or {2} found in {3}'\n\u001b[0m\u001b[1;32m     73\u001b[0m                                     ''.format(star_id, star_id.lstrip('0'), star_id.zfill(6), intermediate_data_directory))\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_list\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: No file with name containing 27321 or 27321 or 027321 found in htof/test/data_for_tests/Hip21"
     ]
    }
   ],
   "source": [
    "from astropy.time import Time\n",
    "from astropy.coordinates import Angle\n",
    "import numpy as np\n",
    "from htof.main import Astrometry\n",
    "import os\n",
    "\n",
    "\n",
    "# Note that including the parallax component is important if you want to recover the catalog errors.\n",
    "pmRA = 4.65  # mas/year\n",
    "pmDec = 81.96  # mas/year\n",
    "# generate fitter and parse intermediate data\n",
    "astro = Astrometry('Hip21', '27321', os.path.join('htof/test/data_for_tests/', 'Hip21'), \n",
    "                   central_epoch_ra=1991.25,\n",
    "                   central_epoch_dec=1991.25, format='jyear', fit_degree=1,\n",
    "                   use_parallax=False)\n",
    "# generate ra and dec for each observation.\n",
    "centered_epochs = Time(astro.data.julian_day_epoch(), format='jd', scale='tcb').jyear - \\\n",
    "                  Time(1991.25, format='decimalyear').jyear\n",
    "ra = Angle(pmRA * centered_epochs, unit='mas')\n",
    "dec = Angle(pmDec * centered_epochs, unit='mas')\n",
    "# add residuals\n",
    "ra += Angle(astro.data.residuals.values * np.sin(astro.data.scan_angle.values), unit='mas')\n",
    "dec += Angle(astro.data.residuals.values * np.cos(astro.data.scan_angle.values), unit='mas')\n",
    "#\n",
    "solution_vector = astro.fit(ra.mas, dec.mas)\n",
    "print(f'four parameter fit to Hip Javatool data:')\n",
    "print('proper motion in ra (mas/yr), proper motion in dec (mas/yr)')\n",
    "ra0, dec0, mu_ra, mu_dec = solution_vector\n",
    "print(mu_ra.round(4), mu_dec.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second way: Separately using data parsers and the fitter class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from htof.parse import HipparcosRereductionDVDBook, HipparcosRereductionJavaTool\n",
    "from htof.fit import AstrometricFitter\n",
    "\n",
    "iad_name = 'Hip21'\n",
    "\n",
    "parser = {'Hip2': HipparcosRereductionDVDBook, 'Hip21': HipparcosRereductionJavaTool}[iad_name]\n",
    "data = parser()\n",
    "data.parse(star_id=27321,\n",
    "           intermediate_data_directory=os.path.join('htof/test/data_for_tests/', iad_name))\n",
    "data.calculate_inverse_covariance_matrices()\n",
    "# generate ra and dec for each observation.\n",
    "jyear_epochs = Time(data.julian_day_epoch(), format='jd', scale='tcb').jyear\n",
    "centered_epochs = jyear_epochs - Time(1991.25, format='decimalyear').jyear\n",
    "ra = Angle(pmRA * centered_epochs, unit='mas')\n",
    "dec = Angle(pmDec * centered_epochs, unit='mas')\n",
    "# add residuals\n",
    "ra += Angle(data.residuals.values * np.sin(data.scan_angle.values), unit='mas')\n",
    "dec += Angle(data.residuals.values * np.cos(data.scan_angle.values), unit='mas')\n",
    "#\n",
    "fitter = AstrometricFitter(inverse_covariance_matrices=data.inverse_covariance_matrix,\n",
    "                           epoch_times=jyear_epochs, central_epoch_dec=1991.25, central_epoch_ra=1991.25)\n",
    "solution_vector = fitter.fit_line(ra.mas, dec.mas)\n",
    "print(f'four parameter fit to {iad_name} data:')\n",
    "print('proper motion in ra (mas/yr), proper motion in dec (mas/yr)')\n",
    "ra0, dec0, mu_ra, mu_dec = solution_vector\n",
    "print(mu_ra.round(4), mu_dec.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Combining astrometric missions for beta pic and extracting the best fit astrometric parameters from the two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from htof.parse import GaiaData, GaiaeDR3, HipparcosOriginalData, DataParser\n",
    "from htof.fit import AstrometricFitter\n",
    "from htof.sky_path import parallactic_motion, earth_ephemeris\n",
    "from astropy import time\n",
    "from astropy.time import Time\n",
    "from astropy.coordinates import Angle\n",
    "from astropy.constants import G\n",
    "import astropy.units as u\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "# relevant star parameters\n",
    "hip_id = '27321'\n",
    "cntr_ra, cntr_dec = Angle(86.82118072, 'degree'), Angle(-51.06671341, 'degree')\n",
    "plx = 1.1 * u.mas # fake parallax\n",
    "# parse Hipparcos 1 data for hip 27321\n",
    "hip1 = HipparcosOriginalData()\n",
    "hip1.parse(star_id=hip_id, intermediate_data_directory='htof/test/data_for_tests/Hip1/IntermediateData')\n",
    "hip1.calculate_inverse_covariance_matrices()\n",
    "\n",
    "# parse Gaia EDR3.\n",
    "gaia = GaiaeDR3()\n",
    "gaia_err = 120/1000  # gaia single measurement error in milli arc second. Should be ~50 to 170 micro arc seconds.\n",
    "gaia.parse(star_id=hip_id, intermediate_data_directory='htof/test/data_for_tests/GaiaeDR3')\n",
    "gaia.along_scan_errs = pd.Series(np.ones(len(gaia), dtype=float) * gaia_err)\n",
    "gaia.calculate_inverse_covariance_matrices()\n",
    "\n",
    "# combine the two missions:\n",
    "data = hip1 + gaia # combined mission data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We are combining Gaia and Hipparcos astrometric missions here. Note that this should be used in an exploratory way or for mission forecasting. In detail one has to place these individual transits into a common reference frame first.\n",
    "\n",
    "### We are creating fake data here with proper motions of .5 mas/yr in ra and 0.1 mas/yr in dec, and a parallax angle of 1.1 mas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the epochs for the fit\n",
    "epochs = data.julian_day_epoch()\n",
    "\n",
    "# generate the parallactic perturbations. For simplicity, assume ngrst and gaia and hipparcos are all in orbit\n",
    "# around earth (even though Gaia is at L2). Really we would want to hstack the parallactic perturbations for each\n",
    "# different ephemeris.\n",
    "jyear_epoch = time.Time(epochs, format='jd', scale='tcb').jyear\n",
    "# pick a central epoch for the fit:\n",
    "central_epoch = 2010\n",
    "ra_motion, dec_motion = parallactic_motion(jyear_epoch, cntr_ra.degree, cntr_dec.degree, 'degree',\n",
    "                                           time.Time(central_epoch, format='decimalyear', scale='tcb').jyear,\n",
    "                                           ephemeris=earth_ephemeris)\n",
    "# ra_motion, dec_motion are the parallax motion alone, for a parallax of 1 mas. I.e., the parallax factors.\n",
    "# note that ra_motion and dec_motion are in degrees here.\n",
    "# generate sky path\n",
    "year_epochs = jyear_epoch - time.Time(central_epoch, format='jyear', scale='tcb').jyear\n",
    "# add a small linear motion (fake proper motion of beta pic) of 5 mas/yr in ra and .1 mas/yr in dec\n",
    "ra = Angle(.5 * year_epochs, unit='mas') + Angle(ra_motion, unit='degree') * plx.value\n",
    "dec = Angle(.1 * year_epochs, unit='mas') + Angle(dec_motion, unit='degree') * plx.value\n",
    "\n",
    "# for large proper motions, ideally you will want to fit iteratively, because there are small numerical round offs\n",
    "# that add up.\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(ra, dec)\n",
    "plt.annotate('Hipparcos', xy=(-10, 0), fontsize=20)\n",
    "plt.annotate('Gaia EDR3', xy=(-1, -1.5), fontsize=20)\n",
    "plt.plot(ra, dec)\n",
    "plt.show()\n",
    "\n",
    "# now we fit with htof.fitter to solve for the proper motions (which will be equal to the input proper motions)\n",
    "# fit_degree = 1 gives a standard 4 parameter fit (position + proper motions), or a 5 parameter fit (parallax, positions, proper motions) if \n",
    "# use_parallax=True and the parallactic components are given.\n",
    "fitter = AstrometricFitter(data.inverse_covariance_matrix, jyear_epoch,\n",
    "                           use_parallax=True, fit_degree=1, central_epoch_ra=central_epoch, \n",
    "                           central_epoch_dec=central_epoch,\n",
    "                           parallactic_pertubations={'ra_plx': Angle(ra_motion, 'degree').mas,\n",
    "                                                     'dec_plx': Angle(dec_motion, 'degree').mas})\n",
    "# fit the standard model\n",
    "astrometric_parameters, errors, chisquared, residuals = fitter.fit_line(ra.mas, dec.mas, return_all=True)\n",
    "print('best fit astometric parameters: [parallax, ra, dec, proper motion ra, proper motion dec]:')\n",
    "print('(mas, mas, mas, mas/yr, mas/yr)')\n",
    "print(astrometric_parameters.round(3))\n",
    "print('Note that we have recovered the input proper motions and parallax.')\n",
    "print('standard errors on the five parameters: [parallax, ra, dec, proper motion ra, proper motion dec]:')\n",
    "print(errors.round(5))\n",
    "print('formal chisquared of the fit (will be near 0 because there is no noise):')\n",
    "print(chisquared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets also compute a variety of interesting parameters concerning this combined astrometric mission:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The covariance matrix of the five astrometric parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covmat = fitter.evaluate_cov_matrix(central_epoch, central_epoch)\n",
    "print(covmat)\n",
    "print('note that the sqrt of the diagonal of the covariance matrix is equal to the standard errors on the parameters from the previous fit (as it should)')\n",
    "print(list(np.sqrt(np.diagonal(covmat)).round(5)))\n",
    "print('standard errors on the five parameters: [parallax, ra, dec, proper motion ra, proper motion dec]:')\n",
    "print(errors.round(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The epochs at which the covariance between ra/pm_ra and dec/pm_dec (position/proper motion) is zero. These are called the central epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_epoch_ra, best_epoch_dec = fitter.find_optimal_central_epoch(coordinate='ra'), fitter.find_optimal_central_epoch(coordinate='dec')\n",
    "print(best_epoch_ra, best_epoch_dec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets check by computing the covariance matrix with those ra and dec epochs, comparing it to the one we computed above with a central epoch of 2010 for both ra and dec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covmatbest = fitter.evaluate_cov_matrix(best_epoch_ra, best_epoch_dec)  # we set the central epoch above to be 2010, and centered the times around it, so we want 0,0 here.\n",
    "print(f'ra/pm_ra covariance at the central epoch {best_epoch_ra : 1f}:')\n",
    "print(covmatbest[1, 3].round(11)) # rounding to the eleventh decimal\n",
    "print('ra/pm_ra covariance at 2010:')\n",
    "print(covmat[1, 3].round(11))\n",
    "\n",
    "print(f'dec/pm_dec covariance at the central epoch {best_epoch_dec: 1f}:')\n",
    "print(covmatbest[2, 4].round(11)) # rounding to the eleventh decimal\n",
    "print('dec/pm_dec covariance at 2010:')\n",
    "print(covmat[2, 4].round(11))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## These \"central epochs\" are very important when the astrometric modelling is crucial. For orbital fits like Gl 229 B, where the astrometric modelling comprises a significant portion of the mass error budget, we need to verify that using the GOST data tool is appropriate.\n",
    "\n",
    "### Comparing the central epochs that htof computes from the GOST data, to those inferred from the Gaia EDR3 archive, will tell us if something is amiss with the GOST data and by how much.\n",
    "### Note that this tells us only if the Gaia GOST approximation is wrong. If this test is passed, then there is nothing obviously wrong, but it does not guarantee that using the GOST data is correct per se... But we cannot do any better --- we will have to wait for the full IAD with gaia DR4 to do better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First lets compute the central epochs that we infer using the GOST predicted scans:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_hip_id = 27321\n",
    "gaia_epoch_ra, gaia_epoch_dec = 2016, 2016 # for EDR3 !\n",
    "\n",
    "\n",
    "# instantiate a gaia edr3 fitter object (so that the inverse covariance matrix etc. are calculated)\n",
    "gaiaedr3astro =  Astrometry('GaiaeDR3', str(object_hip_id), 'htof/test/data_for_tests/GaiaeDR3', \n",
    "                            central_epoch_ra=gaia_epoch_ra, central_epoch_dec=gaia_epoch_dec, format='jyear', \n",
    "                            fit_degree=1, use_parallax=False, normed=False)\n",
    "\n",
    "# printing the central epoch that we get using htof and the Gaia GOST prediction for EDR3:\n",
    "central_epoch = gaiaedr3astro.optimal_central_epochs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### now we load in the actual EDR3 archive ra, dec, covariances etc (the fitted parameters) to compute what the central epoch for EDR3 should be IF we had the full IAD (which we do not!). If this is close to the gost value computed above, then we are OK for using htof in something like orbit fitting with orvara. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOTE: you will need to pip install astroquery for this cell to work. Astroquery is not used anywhere in the source code of htof, so it is not a pre-installed requirement of the package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.coordinates import SkyCoord\n",
    "from astroquery.gaia import Gaia\n",
    "from astroquery.simbad import Simbad\n",
    "from astropy import units\n",
    "\n",
    "Gaia.MAIN_GAIA_TABLE = \"gaiaedr3.gaia_source\"  # Select early Data Release 3\n",
    "\n",
    "def get_gaiaedr3_archive_table(source_name):\n",
    "    # get coordinates of object from SIMBAD\n",
    "    result_table = Simbad.query_object(source_name)\n",
    "    ra, dec = result_table['RA'][0], result_table['DEC'][0]\n",
    "    coordinate = SkyCoord(ra=ra, dec=dec, unit=(u.hourangle, u.deg),\n",
    "                          frame='icrs', equinox='j2000',\n",
    "                          obstime=Time(2000.0, format='decimalyear'))\n",
    "    # use those coordinates to query gaia.\n",
    "    results = Gaia.query_object(coordinate=coordinate, radius=10.0 * units.arcsec)\n",
    "    if len(results) > 1:\n",
    "        results = results[0]\n",
    "    return results\n",
    "\n",
    "print(f'RA: {np.round(central_epoch[\"ra\"], 5)} \\nDEC: {np.round(central_epoch[\"dec\"], 5)}', ' are the htof + GOST predictions for central epochs.')\n",
    "\n",
    "t = get_gaiaedr3_archive_table(f'HIP {object_hip_id}')\n",
    "assert t['source_id'] == 4792774797545800832  # just a manual double check that we indeed did pull Beta pic.\n",
    "# pm_pos_covariance / pm_variance\n",
    "print('catalog:')\n",
    "catalog_central_epoch_ra = 2016 - t['ra_error'] * t['pmra_error'] * t['ra_pmra_corr'] / (t['pmra_error']**2)\n",
    "catalog_central_epoch_dec = 2016 - t['dec_error'] * t['pmdec_error'] * t['dec_pmdec_corr'] / (t['pmdec_error']**2)\n",
    "print(f'RA: {np.round(catalog_central_epoch_ra[0], 5)} \\nDEC: {np.round(catalog_central_epoch_dec[0], 5)}', ' are the values from the Gaia EDR3 Archive')\n",
    "print('diffs:')\n",
    "print(f'RA: {np.round(central_epoch[\"ra\"] - catalog_central_epoch_ra[0], 5)} \\nDEC: {np.round(central_epoch[\"dec\"] - catalog_central_epoch_dec[0], 5)}', ' (years) are the differences')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The difference in RA is minimal (less than 2 days), but the difference in Dec is on the border of being substantial (about 0.1 years). Because the EDR3 baseline is 2.75 years, we can expect this to perhaps induce, naively, a systematic error of 0.1/2.75 = 3.6% . So in any orbital fit (say using orvara), you would want to investigate the detailed effect of this (if there even is any effect) if the mass or orbital parameter constraints are comparable to or better than 3.6%. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: Ad-hoc correction of a data corrupted Hip2 source (using the Java tool IAD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we are going to just parse an hip2.1 (java tool iad) source. Parsing will automatically apply the ad-hoc correction if necessary.\n",
    "# This works for all but 38 sources in the java tool (as of June 24 2021).\n",
    "# An up to date list of the sources for which this does not work \n",
    "# can be found in htof/data/hip2_Javatool_flagged.txt\n",
    "import os\n",
    "from htof.parse import HipparcosRereductionJavaTool\n",
    "\n",
    "test_data_directory = os.path.join(os.getcwd(), 'htof/test/data_for_tests/Hip21')\n",
    "data = HipparcosRereductionJavaTool()\n",
    "# get info on the IAD without doing any rejection:\n",
    "\n",
    "iad_with_header, iad = data.parse(star_id=44050, intermediate_data_directory=test_data_directory, attempt_adhoc_rejection=True)\n",
    "print('Although data is fixed, the IAD that are returned by data parser are untouched. Note that the last 3 along scan errors (last column) are repeated')\n",
    "print(iad)\n",
    "print('length of the iad:', len(iad))\n",
    "print('last ten along scan errors from the uncorrected IAD:')\n",
    "print(iad[6][-10:])\n",
    "\n",
    "print('now lets look at the DataParser object, which is actually fixed.')\n",
    "print('length of the fixed data:', len(data))\n",
    "print('So the fixed data have 71 transits instead of 74, because the 3 bugged epochs have been removed, and orbits have been shuffled.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if you wanted to retrieve the ad-hoc corrected IAD itself (and not use htof any further), you would first parse the source with htof. Then call data.additional_rejected_epochs to tell which epochs (first five columns) should be removed from the IAD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.additional_rejected_epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You would remove the columns (IORB, EPOCH, PARF, CPSI, SPSI) from transits 8, 11 and 44, then slide up the following rows to fit. Then you would remove the last 3 residuals (again because there are 3 corrupted epochs for this source): 73, 72, 71. The resulting IAD is the ad-hoc corrected IAD for this source. Note again, that htof does all of this automatically on .parse(). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "htof does this correction automatically, but will not save a new intermediate data file. Although, you can write out a file of scan angles, times, along scan errors, and residuals (that would be automatically fixed):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_directory = os.path.join(os.getcwd(), 'htof/test/data_for_tests/Hip21')\n",
    "data = HipparcosRereductionJavaTool()\n",
    "# get info on the IAD without doing any rejection:\n",
    "\n",
    "data.parse(star_id=44050, intermediate_data_directory=test_data_directory, attempt_adhoc_rejection=True)\n",
    "data.write('fixed_iad_44050.csv', overwrite=True)\n",
    "print('note that the last column (icov) of this .csv file will just be zeros, because we did not call data.calculate_inverse_covariance_matrices()')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corruptions are present in the DVD data as well. However, for any DVD sources that have regularly rejected epochs the data corruption cannot be fixed: since the rejected epochs are not marked as such it is combinatorially infeasible to apply an ad-hoc correc This leaves ~8000 sources that htof cannot refit (if using the DVD IAD). We recommend that you use the Java tool IAD (as we have done in these examples), because htof can correct nearly every Java tool source."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Example 4: Here we combine some of the above examples to make a figure very similar to Figure 3 from the HTOF paper. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Preliminaries\n",
    "\"\"\"\n",
    "\n",
    "# relevant star parameters\n",
    "hip_id = '27321'\n",
    "cntr_ra, cntr_dec = Angle(86.82118072, 'degree'), Angle(-51.06671341, 'degree')\n",
    "plx = 51.44 * u.mas\n",
    "mass_star = 1.84 * u.solMass\n",
    "########\n",
    "\n",
    "def calc_orbit(varpi, a, inc, Ma, phase, time, multiplier=1):\n",
    "    \"\"\"\n",
    "    :param varpi: parallax angle (units attached)\n",
    "    :param a: semi major axis (units attached)\n",
    "    :param inc: inclination in radians or with unit attached\n",
    "    :param Ma: mass of the primary (units attached)\n",
    "    :param phase: phase of the orbit in radians or with unit attached\n",
    "    :param time: time to evaluate the orbit (units attached), i.e. time.Time(times, format='jd')\n",
    "    :param multiplier: optional multiplier, e.g. -Mb/Ma to calculate the pertubation on the host star.\n",
    "    :return: motion: dict\n",
    "            motion['ra'], motion['dec'] gives the orbit in the plane of the sky with the same units as\n",
    "            the parallax angle varpi.\n",
    "    \"\"\"\n",
    "    # calculate the orbit of the secondary in the center of momentum frame.\n",
    "    # multiply results by -Mb/Ma (b is planet) to get to delta RA and delta Dec for the star.\n",
    "    period = np.sqrt(4*(np.pi**2)*(a)**3 / (G*Ma))\n",
    "    phases = ((2*np.pi)/period.to(u.second) * time.to(u.second)).value * u.rad\n",
    "    amplitude = (((varpi.to(u.arcsec)).value * (a.to(u.pc)).value) * u.rad).to(varpi.unit)\n",
    "    # TODO do I need a cosine delta term here?\n",
    "    return {'dec': multiplier * amplitude * np.cos(inc)*np.cos(phases + phase),\n",
    "            'ra': multiplier * amplitude * np.sin(phases + phase)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User parameters:\n",
    "gaia_err = 120/1000  # gaia single measurement error in milli arc second. Should be ~50 to 170 micro arc seconds.\n",
    "ngrst_err = 10/1000  # single measurement error for the other mission in milli arc second\n",
    "central_epoch = 2020\n",
    "num_phases = 8  # number of orbital phases to averaged over\n",
    "num_inclinations = 4  # number of orbital inclinations to average over\n",
    "\n",
    "num = 6  # number of measurements for the new NGRST mission\n",
    "add_gaia = True  # whether to add gaia data (i.e. a merger of Hipparcos and Gaia)\n",
    "add_ngrst = True  # whether to add NGRST data (i.e. a merger of Hipparcos and Gaia and NGRST)\n",
    "add_hip = True\n",
    "\n",
    "\n",
    "check_orbit = False  # debug\n",
    "\n",
    "#############\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define the epochs for the NGRST mission\n",
    "other_epochs = Time(np.random.uniform(2025, 2030, num), format='jyear')  # measurement epochs for the other mission.\n",
    "separations = np.logspace(-1, np.log10(40), 100) * u.AU\n",
    "\n",
    "\n",
    "# make data parser object for NGRST\n",
    "icovar = np.linalg.pinv(np.array([[ngrst_err**2, 0], [0, ngrst_err**2]]) * np.ones((num, 2, 2)))\n",
    "ngrst = DataParser(epoch=pd.DataFrame(other_epochs.jd), inverse_covariance_matrix=icovar)\n",
    "\n",
    "# parse Hipparcos 1 data for hip 27321\n",
    "hip1 = HipparcosOriginalData()\n",
    "hip1.parse(star_id=hip_id, intermediate_data_directory='htof/test/data_for_tests/Hip1/IntermediateData')\n",
    "hip1.calculate_inverse_covariance_matrices()\n",
    "\n",
    "# parse Gaia full data release data (projected)\n",
    "gaia = GaiaData()\n",
    "gaia.parse(star_id=hip_id, intermediate_data_directory='htof/test/data_for_tests/GaiaDR2')\n",
    "gaia.along_scan_errs = pd.Series(np.ones(len(gaia), dtype=float) * gaia_err)\n",
    "gaia.calculate_inverse_covariance_matrices()\n",
    "\n",
    "data = DataParser()\n",
    "\n",
    "# merge the intermediate data together\n",
    "plot_title = ''\n",
    "if add_hip:\n",
    "    data += hip1\n",
    "    plot_title += 'Hip1 + '\n",
    "if add_gaia:\n",
    "    data += gaia\n",
    "    plot_title += 'Gaia DR4 + '\n",
    "if add_ngrst:\n",
    "    data += ngrst\n",
    "    plot_title += 'NGRST'\n",
    "    \n",
    "\n",
    "# for debug only:\n",
    "if check_orbit:\n",
    "    motion = calc_orbit(51*u.mas, 2.8*u.AU, 0*u.degree, 1.8*u.solMass,\n",
    "                        0*u.degree, np.linspace(0, .9, 100)*u.year,\n",
    "                        multiplier=(8*u.jupiterMass/(1.8*u.solMass)).decompose())\n",
    "    plt.figure()\n",
    "    plt.plot(motion['ra'], motion['dec'])\n",
    "    plt.xlabel('{0}'.format(motion['ra'].unit))\n",
    "    plt.ylabel('{0}'.format(motion['dec'].unit))\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "# get the epochs for the fit\n",
    "epochs = data.julian_day_epoch()\n",
    "\n",
    "# generate the parallactic perturbations. For simplicity, assume ngrst and gaia and hipparcos are all in orbit\n",
    "# around earth (even though Gaia is at L2). Really we would want to hstack the parallactic perturbations for each\n",
    "# different ephemeris.\n",
    "jyear_epoch = time.Time(epochs, format='jd', scale='tcb').jyear\n",
    "ra_motion, dec_motion = parallactic_motion(jyear_epoch, cntr_ra.degree, cntr_dec.degree, 'degree',\n",
    "                                           time.Time(central_epoch, format='decimalyear', scale='tcb').jyear,\n",
    "                                           ephemeris=earth_ephemeris)\n",
    "# note that ra_motion and dec_motion are in degrees here.\n",
    "# generate sky path\n",
    "year_epochs = jyear_epoch - time.Time(central_epoch, format='jyear', scale='tcb').jyear\n",
    "# to avoid numerical issues: set the observed motion to zero. this just assumes you have somehow accounted\n",
    "# for the linear motion and parallax perfectly, and now you want to use HTOF to fit for the remainder.\n",
    "ra = Angle(0 * year_epochs, unit='degree')\n",
    "dec = Angle(0 * year_epochs, unit='degree')\n",
    "\n",
    "# instantiate fitter\n",
    "fitter = AstrometricFitter(data.inverse_covariance_matrix, year_epochs,\n",
    "                           use_parallax=True, fit_degree=1,\n",
    "                           parallactic_pertubations={'ra_plx': Angle(ra_motion, 'degree').mas,\n",
    "                                                     'dec_plx': Angle(dec_motion, 'degree').mas})\n",
    "\n",
    "\n",
    "# define a function to calcluate the chisquared of the fit\n",
    "def calc_chisqds(separations, plx, inc, mass_star, phase, epochs, fitter):\n",
    "    chisqds = []\n",
    "    for separation in separations:\n",
    "        motion = calc_orbit(plx, separation, inc,\n",
    "                            mass_star, phase, epochs)\n",
    "        coeffs, errs, chisq, resids = fitter.fit_line((ra + motion['ra']).mas,\n",
    "                                                      (dec + motion['dec']).mas, return_all=True)\n",
    "        chisqds.append(chisq)\n",
    "    return np.array(chisqds)\n",
    "\n",
    "\n",
    "phases = np.linspace(0, 2*np.pi, num_phases) * u.rad\n",
    "inclinations = np.arcsin(np.linspace(0, 1, num_inclinations)) * u.rad #7\n",
    "if num_inclinations == 1:\n",
    "    inclinations = np.array([np.pi/2]) * u.rad\n",
    "\n",
    "all_chisqds = []\n",
    "for inc in inclinations:\n",
    "    for phase in phases:\n",
    "        all_chisqds.append(calc_chisqds(separations, plx, inc, mass_star, phase,\n",
    "                                        year_epochs*u.year, fitter))\n",
    "\n",
    "chisqds = np.average(all_chisqds, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Now we will use the calculated chisquareds to make a 2d contour plot of the data.\n",
    "\"\"\"\n",
    "\n",
    "###################\n",
    "title_font_size = 28\n",
    "tick_font_size = 32\n",
    "######\n",
    "# setting plot parameters\n",
    "font = {'family' : 'serif',\n",
    "        'size'   : tick_font_size}\n",
    "plt.rc('font', **font)\n",
    "plt.rc('xtick', labelsize='x-small')\n",
    "plt.rc('ytick', labelsize='x-small')\n",
    "plt.rc('mathtext', fontset=\"cm\") # fixing latex fonts\n",
    "#######\n",
    "\n",
    "def resample(x, y, num):\n",
    "    f = interp1d(x, y, kind='linear')\n",
    "    x_lin = np.linspace(np.min(x), np.max(x), num)\n",
    "    return x_lin, f(x_lin)\n",
    "\n",
    "separation_samples = 1000\n",
    "mass_samples = 1000\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "\n",
    "# use the chisquareds and separations \n",
    "separations, chisqds = resample(separations, chisqds, separation_samples) # resample onto log grid\n",
    "masses = np.linspace(1/600, 40, mass_samples) * u.M_jup\n",
    "\n",
    "# generate chisquared array for all the masses\n",
    "chisqds = np.ones((len(masses), len(separations)), dtype=float) * np.array(chisqds)\n",
    "# apply the scaling with the astrometric signal (saves having to calculate the fit over the masses).\n",
    "# This is why we do not calculate chisquared changes in the mass in the previous Cell of this notebook).\n",
    "chisqds *= (((-masses / mass_star).decompose().value).reshape(-1, 1)) ** 2\n",
    "masses = masses.value\n",
    "# plotting contours\n",
    "sigma_contour = np.sqrt(30)\n",
    "X, Y = np.meshgrid(separations.flatten(), masses.flatten())\n",
    "cs1 = ax.contour(X, Y, np.sqrt(chisqds), [sigma_contour], colors='black',\n",
    "linestyles=['solid'], linewidths=5, alpha=0.7)\n",
    "cs2 = ax.contourf(X, Y, np.sqrt(chisqds), [0, sigma_contour, 10000], extend='both',\n",
    "                  colors=['w', 'b'], alpha=0.25)\n",
    "cs2.cmap.set_under('w')\n",
    "cs2.cmap.set_over('b')\n",
    "ax.set_title(plot_title)\n",
    "#ax.clabel(contours, inline=True, fontsize=20, fmt='%1.1f', manual=[(3, 1)], inline_spacing=0)\n",
    "\n",
    "# plotting planets\n",
    "solar_system = [{'mass': 1 / 317.8, 'a': 1, 'name': 'Earth', 'marker': r'$\\oplus$'},\n",
    "                {'mass': 1, 'a': 5.2, 'name': 'Jupiter', 'marker': r'${\\rm J}$'},\n",
    "                {'mass': 17.15 / 317.8, 'a': 30.11, 'name': 'Neptune', 'marker': r'${\\rm N}$'},\n",
    "                {'mass': 95.16 / 317.8, 'a': 9.55, 'name': 'Saturn', 'marker': r'${\\rm S}$'},\n",
    "                {'mass': 14.54 / 317.8, 'a': 19.2, 'name': 'Uranus', 'marker': r'${\\rm U}$'}]\n",
    "betapic = [{'mass': 10, 'a': 9.65, 'name': r'$\\beta~{\\rm Pic~b}$', 'marker': r'$\\beta~{\\rm Pic~b}$',\n",
    "            'merr': 4, 'aerr': .3},\n",
    "           {'mass': 9, 'a': 2.7, 'name': r'$\\beta~{\\rm Pic~c}$', 'marker': r'$\\beta~{\\rm Pic~c}$',\n",
    "            'merr': 4, 'aerr': 0.02},\n",
    "           ]\n",
    "\n",
    "for planet in solar_system:\n",
    "    ax.scatter(planet['a'], planet['mass'], marker=planet['marker'], color='k', label=planet['name'],\n",
    "               s=300, zorder=9)\n",
    "\n",
    "ax.legend(loc='lower left', prop={'size': 20})\n",
    "\n",
    "for planet in betapic:\n",
    "    ax.scatter(planet['a']*0.7, planet['mass'], marker=planet['marker'],\n",
    "               color='k', label=planet['name'],\n",
    "               s=3000, zorder=9)\n",
    "    ax.scatter(planet['a'], planet['mass'], marker='x', color='k', s=10, zorder=9)\n",
    "    ax.errorbar(planet['a'], planet['mass'],\n",
    "                yerr=planet['merr'], xerr=planet['aerr'], zorder=9, color='k')\n",
    "\n",
    "ax.set_yscale('log')\n",
    "ax.set_xscale('log')\n",
    "\n",
    "ax.set_ylabel(r'$M_{Jupiter}$')\n",
    "ax.set_xlabel(r'$a$ (A.U.)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In the weeds with parallax factors:\n",
    "\n",
    "### As you know, the hipparcos IAD includes the parallax factors -- so why does htof compute them freshly? We compute them freshly so you can do experiments like the above, combining hipparcos and gaia together. (Gaia does not curently provide the parallax factors, this will come when its IAD is released). Computing parallax factors anew ensures consistency. But... if you want, you can use the hipparcos parallax factors (which will be nearly identical to the newly computed ones, and will result in the same best fit parameters up to round-off).\n",
    "\n",
    "## Example 5: Using the hipparcos parallax factors that shipped with the IAD.\n",
    "### This is identical to example 1, but we are going to set use_parallax=True and include the keyword use_catalog_parallax_factors=True. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.time import Time\n",
    "from astropy.coordinates import Angle\n",
    "import numpy as np\n",
    "from htof.main import Astrometry\n",
    "import os\n",
    "\n",
    "\n",
    "# Note that including the parallax component is important if you want to recover the catalog errors.\n",
    "pmRA = 4.65  # mas/year\n",
    "pmDec = 83.10  # mas/year\n",
    "# generate fitter and parse intermediate data\n",
    "astro = Astrometry('Hip21', '27321', os.path.join('htof/test/data_for_tests/', 'Hip21'), \n",
    "                   central_epoch_ra=1991.25,\n",
    "                   central_epoch_dec=1991.25, format='jyear', fit_degree=1,\n",
    "                   use_parallax=True, use_catalog_parallax_factors=True)  ### The only difference between example 1!!!\n",
    "# set up residuals\n",
    "ra = Angle(astro.data.residuals.values * np.sin(astro.data.scan_angle.values), unit='mas')\n",
    "dec = Angle(astro.data.residuals.values * np.cos(astro.data.scan_angle.values), unit='mas')\n",
    "# we are just going to fit the residuals here. So the astrometric parameters\n",
    "# that we solve for will actually just be the delta changes to parallax, pmra etc..\n",
    "solution_vector = astro.fit(ra.mas, dec.mas)\n",
    "print(f'five parameter fit to Hip Javatool data:')\n",
    "parallax, ra0, dec0, mu_ra, mu_dec = solution_vector\n",
    "print('\"New\" parallax and proper motions:')\n",
    "print('plx = {:.2f} mas, pmRA = {:.2f} mas/yr, pmDec = {:.2f} mas/yr'.format(51.44 + parallax, pmRA + mu_ra, pmDec + mu_dec))\n",
    "print('Which indeed is identical to the catalog values.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 6: Downloading GOST scanning law data through HTOF.\n",
    "### HTOF data parsers provide an interface to the GOST scanning law directly, without a need to download the files from the web interface.\n",
    "### Downloaded files are then saved in the intermediate data directory provided to the parser.\n",
    "\n",
    "### You must provide the Hipparcos star ID. For instance, if we wanted Hip 49699, we would provide star_id=49699"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaia = GaiaeDR3()\n",
    "gaia.parse(star_id=49699, intermediate_data_directory='./')\n",
    "# the GOST csv file will be saved to intermediate_data_directory for future use. In this case, './'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, not only is the gaia parser object ready to be used, the GOST csv file has been downloaded and saved in the root directory. See for yourself!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('./HIP49699.csv').head(72)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### and compare to the csv file on disc, downloaded from the gost user interface by-hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('htof/test/data_for_tests/GaiaDR2/IntermediateData/HIP049699.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
